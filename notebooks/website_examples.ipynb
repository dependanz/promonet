{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f4dff3-49c9-40fc-8577-7e9f8eb60139",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063d6c49-0a2e-45b7-8eab-05e395a259a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "import itertools\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import IPython.display as ipd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import ppgs\n",
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "import promonet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587145d9-81f1-4fc8-bb07-8a073cdaa2d1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Configuration name\n",
    "ppgs.CONFIG = 'w2v2fb'\n",
    "\n",
    "# Network width\n",
    "ppgs.HIDDEN_CHANNELS = 512\n",
    "\n",
    "# Dimensionality of input representation\n",
    "ppgs.INPUT_CHANNELS = 768\n",
    "\n",
    "# Number of hidden layers\n",
    "ppgs.NUM_HIDDEN_LAYERS = 5\n",
    "\n",
    "# Input representation\n",
    "ppgs.REPRESENTATION = 'w2v2fb'\n",
    "\n",
    "# Local checkpoint to use\n",
    "# If None, Huggingface will be used unless a checkpoint is given in the CLI\n",
    "ppgs.LOCAL_CHECKPOINT = f'/repos/ppgs/runs/w2v2fb/00200000.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac585e74-5477-4c96-99b8-5a9d0f399519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration name\n",
    "ppgs.CONFIG = 'mel'\n",
    "\n",
    "# Network width\n",
    "ppgs.HIDDEN_CHANNELS = 256\n",
    "\n",
    "# Dimensionality of input representation\n",
    "ppgs.INPUT_CHANNELS = 80\n",
    "\n",
    "# Number of hidden layers\n",
    "ppgs.NUM_HIDDEN_LAYERS = 5\n",
    "\n",
    "# Best representation\n",
    "ppgs.BEST_REPRESENTATION = None\n",
    "\n",
    "# Input representation\n",
    "ppgs.REPRESENTATION = 'mel'\n",
    "\n",
    "# Local checkpoint to use\n",
    "# If None, Huggingface will be used unless a checkpoint is given in the CLI\n",
    "ppgs.LOCAL_CHECKPOINT = f'/repos/ppgs/runs/mel/00200000.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd8b17e-eb12-4c24-9c26-bcf401de1fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# promonet.AUGMENT_LOUDNESS = False\n",
    "\n",
    "# # Global input channels\n",
    "# promonet.GLOBAL_CHANNELS = (\n",
    "#     promonet.SPEAKER_CHANNELS +\n",
    "#     promonet.AUGMENT_PITCH +\n",
    "#     promonet.AUGMENT_LOUDNESS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494911e8-fa92-4137-98f2-4243ac4dc896",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'vctk'\n",
    "\n",
    "# Get test stems\n",
    "partition = promonet.load.partition(dataset)\n",
    "if dataset == 'vctk':\n",
    "    stems = partition['test']\n",
    "elif dataset == 'daps':\n",
    "    stems = list(itertools.chain(\n",
    "        *[partition[key] for key in partition.keys()\n",
    "          if key.startswith('test-adapt-')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61eac705-d7e5-434e-95f4-e3a628234925",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# stem = random.choice(stems)\n",
    "# while not stem.startswith('0032'):\n",
    "#     stem = random.choice(stems)\n",
    "stem = '0047/000757'\n",
    "print(stem)\n",
    "speakers = list(set(stem.split('/')[0] for stem in stems))\n",
    "averages = promonet.load.per_speaker_averages()\n",
    "speaker = stem.split('/')[0]\n",
    "if dataset == 'vctk':\n",
    "    checkpoint = promonet.RUNS_DIR / 'promonet' / 'generator-00400000.pt'\n",
    "elif dataset == 'daps':\n",
    "    checkpoint = (\n",
    "        promonet.RUNS_DIR /\n",
    "        'promonet' /\n",
    "        'adapt' /\n",
    "        dataset /\n",
    "        speaker /\n",
    "        'generator-00410000.pt')\n",
    "text = promonet.load.text(promonet.CACHE_DIR / dataset / f'{stem}.txt')\n",
    "audio = promonet.load.audio(promonet.CACHE_DIR / dataset / f'{stem}-100.wav')\n",
    "print(text)\n",
    "ipd.Audio(audio, rate=promonet.SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1f2338-5820-4ac2-83a5-afd31e7b17d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "promonet.convert.samples_to_seconds(audio.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a91bd79-882f-4b96-9df2-20fd2ce74022",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6002ecbf-fded-45d8-9f09-611b47aec1a1",
   "metadata": {},
   "source": [
    "### ProMoNet editing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0397a01-d097-4a1a-abf0-6f5f5552cf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit(\n",
    "    prefix,\n",
    "    audio,\n",
    "    speaker,\n",
    "    target_speaker=None,\n",
    "    edit_kwargs=None,\n",
    "    synthesize_kwargs=None,\n",
    "    save_figure=True,\n",
    "    save_original=True,\n",
    "    method='promonet',\n",
    "    highlight=None\n",
    "):\n",
    "    \"\"\"Edit speech and plot the results\"\"\"\n",
    "    if edit_kwargs is None:\n",
    "        edit_kwargs = {}\n",
    "    if synthesize_kwargs  is None:\n",
    "        synthesize_kwargs = {}\n",
    "\n",
    "    # Preprocess\n",
    "    loudness, pitch, periodicity, ppg = promonet.preprocess.from_audio(\n",
    "        audio,\n",
    "        features=['ppg', 'pitch', 'periodicity', 'loudness'],\n",
    "        gpu=0)\n",
    "\n",
    "    # Edit\n",
    "    (\n",
    "        edited_loudness,\n",
    "        edited_pitch,\n",
    "        edited_periodicity,\n",
    "        edited_ppg,\n",
    "        grid\n",
    "    ) = promonet.edit.from_features(\n",
    "        loudness,\n",
    "        pitch,\n",
    "        periodicity,\n",
    "        ppg,\n",
    "        return_grid=True,\n",
    "        **edit_kwargs)\n",
    "\n",
    "    # Synthesize\n",
    "    if method == 'world':\n",
    "        synthesis_fn = functools.partial(\n",
    "            promonet.baseline.world.from_audio,\n",
    "            pitch=edited_pitch.cpu(),\n",
    "            periodicity=edited_periodicity.cpu())\n",
    "        edited = synthesis_fn(\n",
    "            audio.cpu(),\n",
    "            promonet.SAMPLE_RATE,\n",
    "            grid=grid.cpu())\n",
    "    elif method == 'promonet':\n",
    "        edited = promonet.synthesize.from_features(\n",
    "            edited_loudness,\n",
    "            edited_pitch,\n",
    "            edited_periodicity,\n",
    "            edited_ppg,\n",
    "            speaker=int(speaker),\n",
    "            checkpoint=checkpoint,\n",
    "            gpu=0,\n",
    "            **synthesize_kwargs)\n",
    "\n",
    "    # Plot and save results\n",
    "    plot(\n",
    "        prefix,\n",
    "        audio,\n",
    "        edited,\n",
    "        edited_loudness,\n",
    "        edited_pitch,\n",
    "        edited_periodicity,\n",
    "        edited_ppg,\n",
    "        save_figure,\n",
    "        save_original,\n",
    "        highlight)\n",
    "\n",
    "\n",
    "def plot(\n",
    "    prefix,\n",
    "    audio,\n",
    "    edited,\n",
    "    edited_loudness,\n",
    "    edited_pitch,\n",
    "    edited_periodicity,\n",
    "    edited_ppg,\n",
    "    save_figure=True,\n",
    "    save_original=True,\n",
    "    highlight=None\n",
    "):\n",
    "    \"\"\"Plot overlay of features from input and synthesized audio\"\"\"\n",
    "    # Preprocess synthesized audio\n",
    "    (\n",
    "        predicted_loudness,\n",
    "        predicted_pitch,\n",
    "        predicted_periodicity,\n",
    "        predicted_ppg\n",
    "    ) = promonet.preprocess.from_audio(\n",
    "        edited,\n",
    "        features=['ppg', 'pitch', 'periodicity', 'loudness'],\n",
    "        gpu=0)\n",
    "\n",
    "    # Make audio player\n",
    "    ipd.display(ipd.Audio(audio.cpu(), rate=promonet.SAMPLE_RATE))\n",
    "    ipd.display(ipd.Audio(edited.cpu(), rate=promonet.SAMPLE_RATE))\n",
    "\n",
    "    # Make plot\n",
    "    figure = promonet.plot.from_features(\n",
    "        audio,\n",
    "        promonet.preprocess.loudness.band_average(edited_loudness, 1),\n",
    "        edited_pitch,\n",
    "        edited_periodicity,\n",
    "        edited_ppg,\n",
    "        promonet.preprocess.loudness.band_average(predicted_loudness, 1),\n",
    "        predicted_pitch,\n",
    "        predicted_periodicity,\n",
    "        predicted_ppg,\n",
    "        features=['ppg', 'pitch', 'periodicity', 'loudness'],\n",
    "        highlight=highlight)\n",
    "\n",
    "    # Save\n",
    "    prefix = Path(prefix)\n",
    "    prefix.parent.mkdir(exist_ok=True, parents=True)\n",
    "    if save_original:\n",
    "        original = prefix.parent / 'Original' / prefix.name\n",
    "        original.parent.mkdir(exist_ok=True, parents=True)\n",
    "        torchaudio.save(f'{original}.wav', audio.cpu(), promonet.SAMPLE_RATE)\n",
    "    if save_figure:\n",
    "        figure.savefig(\n",
    "            prefix.parent / f'{prefix.name}.png',\n",
    "            bbox_inches='tight',\n",
    "            pad_inches=0,\n",
    "            transparent=True)\n",
    "        figure.savefig(\n",
    "            prefix.parent / f'{prefix.name}.pdf',\n",
    "            bbox_inches='tight',\n",
    "            pad_inches=0)\n",
    "    torchaudio.save(f'{prefix}.wav', edited.cpu(), promonet.SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59ac94e-9ffb-4788-8d3c-4b86d8ad1921",
   "metadata": {},
   "source": [
    "### Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215ab65c-a722-4147-a522-0be98f0fb8ee",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "loudness, pitch, periodicity, ppg = promonet.preprocess.from_audio(\n",
    "    audio,\n",
    "    features=['ppg', 'pitch', 'periodicity', 'loudness'],\n",
    "    gpu=0)\n",
    "figure = promonet.plot.from_features(\n",
    "    audio,\n",
    "    promonet.preprocess.loudness.band_average(loudness, 1),\n",
    "    pitch,\n",
    "    periodicity,\n",
    "    ppg,\n",
    "    features=['ppg', 'pitch', 'periodicity', 'loudness'])\n",
    "# figure.savefig(f'original.png', bbox_inches='tight', pad_inches=0, transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eefbd9b-c0a9-443b-939e-0d1618436e0f",
   "metadata": {},
   "source": [
    "### Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2375925-0497-4f6a-b3e4-cc5cb42141db",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "file = (\n",
    "    promonet.EVAL_DIR /\n",
    "    'subjective' /\n",
    "    'mels-ours' /\n",
    "    f'vctk-{stem.replace(\"/\", \"-\")}-original-100.wav')\n",
    "mel_audio = promonet.load.audio(file)\n",
    "loudness, pitch, periodicity, ppg = promonet.preprocess.from_audio(\n",
    "    audio,\n",
    "    features=['ppg', 'pitch', 'periodicity', 'loudness'],\n",
    "    gpu=0)\n",
    "plot(\n",
    "    f'reconstruction/Mels/{tag}',\n",
    "    audio,\n",
    "    mel_audio,\n",
    "    loudness,\n",
    "    pitch,\n",
    "    periodicity,\n",
    "    ppg,\n",
    "    save_figure=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706b7925-a3c7-4cf6-8999-09077846cb9b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "edit(\n",
    "    # f'{\"reconstruction\" if dataset == \"vctk\" else \"adaptation\"}/Proposed/{tag}',\n",
    "    'thesis/reconstruction',\n",
    "    audio,\n",
    "    speaker if dataset == 'vctk' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7715f02f-80dd-4339-bcce-252ce3219dfb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Preprocess\n",
    "loudness, pitch, periodicity, ppg = promonet.preprocess.from_audio(\n",
    "    audio,\n",
    "    features=['ppg', 'pitch', 'periodicity', 'loudness'],\n",
    "    gpu=0)\n",
    "\n",
    "# Synthesize\n",
    "edited = promonet.synthesize.from_features(\n",
    "    loudness,\n",
    "    pitch,\n",
    "    periodicity,\n",
    "    ppg,\n",
    "    speaker=int(speaker),\n",
    "    checkpoint=checkpoint,\n",
    "    gpu=0)\n",
    "\n",
    "# Preprocess synthesized audio\n",
    "(\n",
    "    predicted_loudness,\n",
    "    predicted_pitch,\n",
    "    predicted_periodicity,\n",
    "    predicted_ppg\n",
    ") = promonet.preprocess.from_audio(\n",
    "    edited,\n",
    "    features=['ppg', 'pitch', 'periodicity', 'loudness'],\n",
    "    gpu=0)\n",
    "\n",
    "# Make audio player\n",
    "ipd.display(ipd.Audio(audio.cpu(), rate=promonet.SAMPLE_RATE))\n",
    "ipd.display(ipd.Audio(edited.cpu(), rate=promonet.SAMPLE_RATE))\n",
    "\n",
    "# Save original plot\n",
    "figure = promonet.plot.from_features(\n",
    "    audio,\n",
    "    promonet.preprocess.loudness.band_average(loudness, 1),\n",
    "    pitch,\n",
    "    periodicity,\n",
    "    ppg,\n",
    "    features=['ppg', 'pitch', 'periodicity', 'loudness'])\n",
    "prefix = Path('thesis/reconstruction')\n",
    "prefix.mkdir(exist_ok=True, parents=True)\n",
    "torchaudio.save(prefix / 'original.wav', audio.cpu(), promonet.SAMPLE_RATE)\n",
    "figure.savefig(\n",
    "    prefix / 'original.png',\n",
    "    bbox_inches='tight',\n",
    "    pad_inches=0,\n",
    "    transparent=True)\n",
    "figure.savefig(\n",
    "    prefix / 'original.pdf',\n",
    "    bbox_inches='tight',\n",
    "    pad_inches=0)\n",
    "\n",
    "# Save reconstruction plot\n",
    "figure = promonet.plot.from_features(\n",
    "    edited,\n",
    "    promonet.preprocess.loudness.band_average(predicted_loudness, 1),\n",
    "    predicted_pitch,\n",
    "    predicted_periodicity,\n",
    "    predicted_ppg,\n",
    "    features=['ppg', 'pitch', 'periodicity', 'loudness'])\n",
    "prefix = Path('thesis/reconstruction')\n",
    "prefix.mkdir(exist_ok=True, parents=True)\n",
    "torchaudio.save(prefix / 'reconstructed.wav', audio.cpu(), promonet.SAMPLE_RATE)\n",
    "figure.savefig(\n",
    "    prefix / 'reconstructed.png',\n",
    "    bbox_inches='tight',\n",
    "    pad_inches=0,\n",
    "    transparent=True)\n",
    "figure.savefig(\n",
    "    prefix / 'reconstructed.pdf',\n",
    "    bbox_inches='tight',\n",
    "    pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cd0057-886d-4b2a-9192-f2a3274e8915",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "figure, axis = plt.subplots(1, 1, figsize=(9, 2.25))\n",
    "axis.plot(edited.squeeze().cpu(), color='black', linewidth=.5)\n",
    "axis.set_xmargin(0.)\n",
    "axis.spines['top'].set_visible(False)\n",
    "axis.spines['right'].set_visible(False)\n",
    "axis.spines['bottom'].set_visible(False)\n",
    "axis.spines['left'].set_visible(False)\n",
    "axis.set_xticks([])\n",
    "axis.set_yticks([])\n",
    "axis.set_ylim([-1., 1.])\n",
    "axis.tick_params(axis=u'both', which=u'both', length=0)\n",
    "figure.savefig('thesis/reconstruction/reconstructed-audio.png', bbox_inches='tight', pad_inches=0, transparent=True)\n",
    "# for tick in [-1., 1.]:\n",
    "#     axis.hlines(tick, xmin=0., xmax=audio.shape[-1], color='#aaaa', linestyle='--')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df9e893-ac47-46d6-8ab0-b606c8b8dfdb",
   "metadata": {},
   "source": [
    "### Pitch shifting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113e98bd-a721-46bc-bb2f-f21eca7044fd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "edit(f'thesis/Proposed (+600¢)', audio, speaker, highlight='pitch', edit_kwargs={'pitch_shift_cents': 600.})\n",
    "edit(f'thesis/Proposed (-600¢)', audio, speaker, highlight='pitch', edit_kwargs={'pitch_shift_cents': -600.})\n",
    "# edit(f'pitch-shifting/WORLD (+600¢)/{tag}', audio, speaker, save_figure=False, edit_kwargs={'pitch_shift_cents': 600.}, method='world')\n",
    "# edit(f'pitch-shifting/WORLD (-600¢)/{tag}', audio, speaker, save_figure=False, edit_kwargs={'pitch_shift_cents': -600.}, me|thod='world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d65693f-e66d-4337-9b93-8275021f27af",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "edit(f'pitch-range/_/-1200¢', audio, speaker, save_original=False, save_figure=False, edit_kwargs={'pitch_shift_cents': -1200.})\n",
    "edit(f'pitch-range/_/-600¢', audio, speaker, save_original=False, save_figure=False, edit_kwargs={'pitch_shift_cents': -600.})\n",
    "torchaudio.save(f'pitch-range/_/Original.wav', audio, promonet.SAMPLE_RATE)\n",
    "edit(f'pitch-range/_/+600¢', audio, speaker, save_original=False, save_figure=False, edit_kwargs={'pitch_shift_cents': 600.})\n",
    "edit(f'pitch-range/_/+1200¢', audio, speaker, save_original=False, save_figure=False, edit_kwargs={'pitch_shift_cents': 1200.})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4056ff-0e68-471d-a61d-3b57ff3ebc3b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "original_audio = promonet.load.audio('pitch-range/_/Original.wav')\n",
    "original_pitch, original_periodicity = promonet.preprocess.from_audio(\n",
    "    original_audio,\n",
    "    features=['pitch', 'periodicity'],\n",
    "    gpu=0)\n",
    "original_pitch = original_pitch.cpu().squeeze()\n",
    "original_periodicity = original_periodicity.cpu().squeeze()\n",
    "voiced = original_periodicity > promonet.VOICING_THRESHOLD\n",
    "original_pitch[~voiced] = float('nan')\n",
    "time = torch.linspace(0, len(original_pitch) * (promonet.HOPSIZE / promonet.SAMPLE_RATE), len(original_pitch))\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(time, original_pitch, label='Original', color='black')\n",
    "for spine in plt.gca().spines.values():\n",
    "    spine.set_visible(False)\n",
    "\n",
    "colors = ['blue', 'orange', 'red', 'green']\n",
    "for color, file in zip(colors, Path('pitch-range/_/').glob('*¢.wav')):\n",
    "    cents = float(file.stem[:-1])\n",
    "    ratio = promonet.convert.cents_to_ratio(cents)\n",
    "    x = promonet.load.audio(file)\n",
    "    y = promonet.preprocess.from_audio(\n",
    "        x,\n",
    "        features=['pitch'],\n",
    "        gpu=0)[0].cpu().squeeze()\n",
    "    plt.plot(time, original_pitch * ratio, label=file.stem, color=color)\n",
    "    y[~voiced] = float('nan')\n",
    "    plt.plot(time, y, color=color, linestyle='--')\n",
    "plt.yscale('symlog')\n",
    "plt.yticks([50, 100, 200], ['50', '100', '200'])\n",
    "plt.ylim(40., 350.)\n",
    "plt.xlim(0, 11)\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "order = [4, 3, 0, 2, 1]\n",
    "plt.legend([handles[idx] for idx in order],[labels[idx] for idx in order], frameon=False, fontsize=12)\n",
    "plt.xlabel('Time (seconds)', fontsize=16)\n",
    "plt.ylabel('Pitch (Hz)', fontsize=16)\n",
    "\n",
    "for tick in plt.yticks()[0]:\n",
    "    plt.hlines(tick, 0, time[-1], color='gray', linestyle='dotted', alpha=.25)\n",
    "\n",
    "plt.savefig('pitch-range/pitch-range.png', bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a35424-3507-4d6a-9a4d-32c107d0369d",
   "metadata": {},
   "source": [
    "### Time-stretching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d58d021-1b23-4ce4-9610-640a9ca611e1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "edit(f'thesis/Proposed (1.41x)', audio, speaker, highlight='duration', edit_kwargs={'time_stretch_ratio': 1.41})\n",
    "edit(f'thesis/Proposed (0.71x)', audio, speaker, highlight='duration', edit_kwargs={'time_stretch_ratio': 0.71})\n",
    "# edit(f'time-stretching/WORLD (1.41x)/{tag}', audio, speaker, save_figure=False, edit_kwargs={'time_stretch_ratio': 1.41}, method='world')\n",
    "# edit(f'time-stretching/WORLD (0.71x)/{tag}', audio, speaker, save_figure=False, edit_kwargs={'time_stretch_ratio': 0.71}, method='world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f570d87-94bc-474c-a2df-058c689fd49d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "edit(f'time-range/_/0.50x', audio, speaker, save_original=False, save_figure=False, edit_kwargs={'time_stretch_ratio': 0.50})\n",
    "edit(f'time-range/_/0.71x', audio, speaker, save_original=False, save_figure=False, edit_kwargs={'time_stretch_ratio': 0.71})\n",
    "torchaudio.save(f'time-range/_/Original.wav', audio, promonet.SAMPLE_RATE)\n",
    "edit(f'time-range/_/1.41x', audio, speaker, save_original=False, save_figure=False, edit_kwargs={'time_stretch_ratio': 1.41})\n",
    "edit(f'time-range/_/2.00x', audio, speaker, save_original=False, save_figure=False, edit_kwargs={'time_stretch_ratio': 2.00})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0bc6b2-2663-4876-9a47-d35682987f85",
   "metadata": {},
   "source": [
    "### Perceptual loudness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1857ae77-ef7f-4750-a02c-f52b74c60e64",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "stem_map = {\n",
    "    'Male 1': '0016/000342',\n",
    "    'Male 2': '0047/000540',\n",
    "    'Female 1': '0082/000402',\n",
    "    'Female 2': '0013/000022'\n",
    "}\n",
    "for tag, stem in stem_map.items():\n",
    "    speaker = stem.split('/')[0]\n",
    "    text = promonet.load.text(promonet.CACHE_DIR / dataset / f'{stem}.txt')\n",
    "    audio = promonet.load.audio(promonet.CACHE_DIR / dataset / f'{stem}-100.wav')\n",
    "    print(text)\n",
    "    ipd.display(ipd.Audio(audio, rate=promonet.SAMPLE_RATE))\n",
    "    edit_fn = functools.partial(\n",
    "        edit,\n",
    "        audio=audio,\n",
    "        speaker=speaker,\n",
    "        save_figure=False)\n",
    "    edit_fn(f'loudness/No augment (-10 dBA)/{tag}', edit_kwargs={'loudness_scale_db': -10.})\n",
    "    edit_fn(f'loudness/No augment (+10 dBA)/{tag}', edit_kwargs={'loudness_scale_db': 10.})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a93b88b-bb9d-4a4c-91c4-5cab2d95f4b1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "edit_fn = functools.partial(\n",
    "    edit,\n",
    "    audio=audio,\n",
    "    speaker=speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cd574f-5737-42a4-b449-ea43f337649e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "edit_fn(f'thesis/Proposed (reconstruction)')\n",
    "edit_fn(f'thesis/Proposed (-10 dBA)', highlight='loudness', edit_kwargs={'loudness_scale_db': -10.})\n",
    "edit_fn(f'thesis/Proposed (+10 dBA)', highlight='loudness', edit_kwargs={'loudness_scale_db': 10.})\n",
    "# edit_fn(f'thesis/r_l = 2.0/{tag}', synthesize_kwargs={'loudness_ratio': 2.0})\n",
    "# edit_fn(f'thesis/r_l = 0.5/{tag}', synthesize_kwargs={'loudness_ratio': 0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdacf96-6cd5-48f8-99c7-85931c33b4e6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "original = promonet.load.audio('thesis/Original/Proposed (-10 dBA).wav')\n",
    "reconstructed = promonet.load.audio('thesis/Proposed (reconstruction).wav')\n",
    "quiet = promonet.load.audio('thesis/Proposed (-10 dBA).wav')\n",
    "loud = promonet.load.audio('thesis/Proposed (+10 dBA).wav')\n",
    "\n",
    "def spectra(x, volume_match_with=None):\n",
    "    if volume_match_with is not None:\n",
    "        loudness = promonet.preprocess.loudness.from_audio(x)\n",
    "        original_loudness = promonet.preprocess.loudness.from_audio(volume_match_with)\n",
    "        gain = original_loudness - loudness\n",
    "        x = promonet.preprocess.loudness.limit(promonet.preprocess.loudness.shift(x, gain))\n",
    "    spectrogram = promonet.preprocess.spectrogram.from_audio(x)\n",
    "    return spectrogram.squeeze().mean(dim=-1)[1:]\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "frequencies = torch.abs(torch.fft.fftfreq(\n",
    "    promonet.NUM_FFT,\n",
    "    1 / promonet.SAMPLE_RATE\n",
    ")[1:promonet.NUM_FFT // 2 + 1])\n",
    "# plt.plot(frequencies[1:], spectra(original)[1:], label='Original', linewidth=2)\n",
    "plt.plot(frequencies[1:], spectra(reconstructed, original)[1:], label='Reconstruction', linewidth=2)\n",
    "plt.plot(frequencies[1:], spectra(quiet, original)[1:], label='−10 dBA', linewidth=2)\n",
    "plt.plot(frequencies[1:], spectra(loud, original)[1:], label='+10 dBA', linewidth=2)\n",
    "plt.xlabel('Frequency (Hz)', fontsize=14)\n",
    "plt.ylabel('Energy (dB)', fontsize=14)\n",
    "plt.ylim(0, 5)\n",
    "xticks = [50, 100, 200, 400, 800, 1600, 3200, 6400]\n",
    "plt.xscale('symlog')\n",
    "plt.xticks(xticks, [str(tick) for tick in xticks], fontsize=14)\n",
    "plt.yticks(*plt.yticks(), fontsize=14)\n",
    "plt.xlim(promonet.FMIN * .9, promonet.SAMPLE_RATE // 2)\n",
    "for spine in plt.gca().spines.values():\n",
    "    spine.set_visible(False)\n",
    "for tick in plt.yticks()[0]:\n",
    "    plt.hlines(tick, xmin=1.1 * frequencies[1], xmax=frequencies[-1], color='#aaaa', linestyle='--')\n",
    "plt.tick_params(\n",
    "    axis='y',\n",
    "    which='both',\n",
    "    bottom=False,\n",
    "    top=False,\n",
    "    labelbottom=False,\n",
    "    pad=0,\n",
    "    length=0)\n",
    "plt.legend(frameon=False, fontsize=12)\n",
    "plt.savefig('spectra.pdf', bbox_inches='tight', pad_inches=.1)\n",
    "plt.savefig('spectra.png', bbox_inches='tight', pad_inches=.1, transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5018d566-89aa-44dd-ae1d-9bbe7999d971",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "edit_fn(f'loudness-range/_/-10dBA', save_original=False, edit_kwargs={'loudness_scale_db': -10.})\n",
    "edit_fn(f'loudness-range/_/-5dBA', save_original=False, edit_kwargs={'loudness_scale_db': -5.})\n",
    "torchaudio.save(f'loudness-range/_/Original.wav', audio, promonet.SAMPLE_RATE)\n",
    "edit_fn(f'loudness-range/_/+5dBA', save_original=False, edit_kwargs={'loudness_scale_db': 5.})\n",
    "edit_fn(f'loudness-range/_/+10dBA', save_original=False, edit_kwargs={'loudness_scale_db': 10.})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e79c4f-4c05-45a8-99a0-947d27a68ff4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "original_audio = promonet.load.audio('loudness-range/_/Original.wav')\n",
    "original_loudness = promonet.preprocess.from_audio(\n",
    "    original_audio,\n",
    "    features=['loudness'],\n",
    "    gpu=0,\n",
    "    loudness_bands=1)[0]\n",
    "original_loudness = original_loudness.cpu().squeeze()\n",
    "time = torch.linspace(0, len(original_loudness) * (promonet.HOPSIZE / promonet.SAMPLE_RATE), len(original_loudness))\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(time, original_loudness, label='Original', color='black')\n",
    "for spine in plt.gca().spines.values():\n",
    "    spine.set_visible(False)\n",
    "\n",
    "colors = ['blue', 'orange', 'red', 'green']\n",
    "for color, file in zip(colors, Path('loudness-range/_/').glob('*dBA.wav')):\n",
    "    decibels = float(file.stem[:-3])\n",
    "    x = promonet.load.audio(file)\n",
    "    y = promonet.preprocess.from_audio(\n",
    "        x,\n",
    "        features=['loudness'],\n",
    "        gpu=0,\n",
    "        loudness_bands=1)[0].cpu().squeeze()\n",
    "    plt.plot(time, original_loudness + decibels, label=file.stem, color=color)\n",
    "    plt.plot(time, y, color=color, linestyle='--')\n",
    "# plt.yscale('symlog')\n",
    "# plt.yticks([50, 100, 200], ['50', '100', '200'])\n",
    "# plt.ylim(40., 350.)\n",
    "# plt.xlim(0, 11)\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "order = [4, 3, 0, 2, 1]\n",
    "plt.legend([handles[idx] for idx   in order],[labels[idx] for idx in order], frameon=False, fontsize=12)\n",
    "plt.xlabel('Time (seconds)', fontsize=16)\n",
    "# plt.legend()\n",
    "plt.ylabel('Loudness (dBA)', fontsize=16)\n",
    "\n",
    "for tick in plt.yticks()[0]:\n",
    "    plt.hlines(tick, 0, time[-1], color='gray', linestyle='dotted', alpha=.25)\n",
    "\n",
    "plt.savefig('loudness-range/loudness-range.png', bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea753dc8-8857-4929-bc46-739471320cef",
   "metadata": {},
   "source": [
    "### Voice conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92eeebdb-d8d4-4853-aa25-4f0ef5eea28b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select a random target speaker\n",
    "target_speaker = speaker\n",
    "# target_speaker == '0032'\n",
    "while target_speaker == speaker:\n",
    "    target_speaker = random.choice(speakers)\n",
    "mean_difference_cents = promonet.convert.ratio_to_cents(averages[target_speaker] / averages[speaker])\n",
    "print(averages[speaker], averages[target_speaker], mean_difference_cents)\n",
    "target_sample_stem = random.choice(\n",
    "    [stem for stem in stems if stem.startswith(target_speaker)])\n",
    "# target_sample_stem = '0032/000734'\n",
    "target_sample = promonet.load.audio(\n",
    "    promonet.CACHE_DIR /\n",
    "    'vctk' /\n",
    "    f'{target_sample_stem}-100.wav')\n",
    "ipd.display(ipd.Audio(target_sample.cpu(), rate=promonet.SAMPLE_RATE))\n",
    "print(target_sample_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203f7e4d-fc09-46a5-a0c2-38319ef4dc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = promonet.load.audio('../yawn.wav')\n",
    "\n",
    "edit(\n",
    "    'thesis/yawn',\n",
    "    audio,\n",
    "    target_speaker,\n",
    "    # edit_kwargs={'pitch_shift_cents': mean_difference_cents},\n",
    "    save_original=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f433930-0beb-4d69-9140-c935a358c0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit speaker\n",
    "# target_directory = Path('thesis/Target')\n",
    "# source_directory = Path('thesis/Source')\n",
    "# target_directory.mkdir(exist_ok=True, parents=True)\n",
    "# source_directory.mkdir(exist_ok=True, parents=True)\n",
    "torchaudio.save('thesis/target.wav', target_sample, promonet.SAMPLE_RATE)\n",
    "torchaudio.save('thesis/source.wav', audio, promonet.SAMPLE_RATE)\n",
    "edit(\n",
    "    'thesis/proposed',\n",
    "    audio,\n",
    "    target_speaker,\n",
    "    edit_kwargs={'pitch_shift_cents': mean_difference_cents},\n",
    "    save_original=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45c102e-206c-41c6-827f-0942aeb8a9e2",
   "metadata": {},
   "source": [
    "### Formant editing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f000d248-8267-4853-932f-d5c21a5acd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "edit(f'thesis/Proposed (r_f = 1.41)', audio, speaker, highlight='ppg', synthesize_kwargs={'formant_ratio': 1.41})\n",
    "edit(f'thesis/Proposed (r_f = 0.71)', audio, speaker, highlight='ppg', synthesize_kwargs={'formant_ratio': 0.71})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988a12a9-2afe-491b-aa8e-1801f89688f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure, axes = plt.subplots(\n",
    "#     1,\n",
    "#     1,\n",
    "#     figsize=(6, 2))\n",
    "\n",
    "# Formant pronunciation breakout figure\n",
    "down = promonet.load.audio('thesis/Proposed (r_f = 0.71).wav')\n",
    "up = promonet.load.audio('thesis/Proposed (r_f = 1.41).wav')\n",
    "\n",
    "# Get PPGs\n",
    "loudness, pitch, periodicity, ppg = promonet.preprocess.from_audio(\n",
    "    audio,\n",
    "    features=['ppg', 'pitch', 'periodicity', 'loudness'],\n",
    "    gpu=0)\n",
    "ppg_down = promonet.preprocess.from_audio(down, features=['ppg'], gpu=0)[0]\n",
    "ppg_up = promonet.preprocess.from_audio(up, features=['ppg'], gpu=0)[0]\n",
    "\n",
    "# Compute differences\n",
    "threshold = .35\n",
    "delta_down = (ppg - ppg_down)\n",
    "delta_down_inverse = -delta_down\n",
    "delta_down[delta_down < 0.] = 0.\n",
    "delta_down_inverse[delta_down_inverse < 0.] = 0.\n",
    "mask = torch.logical_and(delta_down < (1 - threshold), delta_down_inverse < (1 - threshold))\n",
    "delta_down[mask] = 0.\n",
    "delta_down_inverse[mask] = 0.\n",
    "\n",
    "delta_up = (ppg - ppg_up)\n",
    "delta_up_inverse = -delta_up\n",
    "delta_up[delta_up < 0.] = 0.\n",
    "delta_up_inverse[delta_up_inverse < 0.] = 0.\n",
    "mask = torch.logical_and(delta_up < (1 - threshold), delta_up_inverse < (1 - threshold))\n",
    "delta_up[mask] = 0.\n",
    "delta_up_inverse[mask] = 0.\n",
    "\n",
    "# Make plot\n",
    "figure = promonet.plot.from_features(\n",
    "    audio,\n",
    "    promonet.preprocess.loudness.band_average(loudness, 1),\n",
    "    pitch,\n",
    "    periodicity,\n",
    "    delta_down,\n",
    "    promonet.preprocess.loudness.band_average(loudness, 1),\n",
    "    pitch,\n",
    "    periodicity,\n",
    "    delta_down_inverse,\n",
    "    features=['ppg'],\n",
    "    ppg_threshold=1 - threshold)\n",
    "figure.savefig('thesis/formant-breakout-down.pdf', bbox_inches='tight', pad_inches=0)\n",
    "figure.savefig('thesis/formant-breakout-down.png', bbox_inches='tight', pad_inches=0, transparent=True)\n",
    "\n",
    "figure = promonet.plot.from_features(\n",
    "    audio,\n",
    "    promonet.preprocess.loudness.band_average(loudness, 1),\n",
    "    pitch,\n",
    "    periodicity,\n",
    "    delta_up,\n",
    "    promonet.preprocess.loudness.band_average(loudness, 1),\n",
    "    pitch,\n",
    "    periodicity,\n",
    "    delta_up_inverse,\n",
    "    features=['ppg'],\n",
    "    ppg_threshold=1 - threshold)\n",
    "figure.savefig('thesis/formant-breakout-up.pdf', bbox_inches='tight', pad_inches=0)\n",
    "figure.savefig('thesis/formant-breakout-up.png', bbox_inches='tight', pad_inches=0, transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e2badd-a94a-43f2-bfb0-62cb39c4656d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ppg_down.squeeze()[ppgs.PHONEMES.index('th')].cpu())\n",
    "plt.plot(ppg.squeeze()[ppgs.PHONEMES.index('dh')].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c334ce4-64ad-4158-a9d9-446bb648892e",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_down.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881ee6e3-649a-4161-9d0c-ce893dfc9e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(delta_down.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc6c48d-b504-4a6a-853c-274d7e270194",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "edit(f'formant-range/_/r_f = 0.50', audio, speaker, save_original=False, save_figure=False, synthesize_kwargs={'formant_ratio': 0.51})\n",
    "edit(f'formant-range/_/r_f = 0.71', audio, speaker, save_original=False, save_figure=False, synthesize_kwargs={'formant_ratio': 0.71})\n",
    "torchaudio.save(f'formant-range/_/Original.wav', audio, promonet.SAMPLE_RATE)\n",
    "edit(f'formant-range/_/r_f = 1.41', audio, speaker, save_original=False, save_figure=False, synthesize_kwargs={'formant_ratio': 1.41})\n",
    "edit(f'formant-range/_/r_f = 2.00', audio, speaker, save_original=False, save_figure=False, synthesize_kwargs={'formant_ratio': 1.99})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f41b033-69a6-4a0a-9f8a-34c3fecd5c7b",
   "metadata": {},
   "source": [
    "### Accent editing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7d5b6a-0206-4dc0-9d0e-1e15deb92564",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Load\n",
    "# audio = promonet.load.audio('/hemera-storage1/pardo/max/test-audio/ill-be-back-denoise.wav')\n",
    "\n",
    "# Preprocess\n",
    "loudness, pitch, periodicity, ppg = promonet.preprocess.from_audio(\n",
    "    audio,\n",
    "    features=['ppg', 'pitch', 'periodicity', 'loudness'],\n",
    "    gpu=0)\n",
    "# log_mean_f0 = torch.log2(pitch[periodicity > promonet.VOICING_THRESHOLD]).mean()\n",
    "# mean_difference_cents = promonet.convert.ratio_to_cents(2 ** log_mean_f0 / averages[speaker])\n",
    "# print(mean_difference_cents)\n",
    "# pitch = pitch * promonet.convert.cents_to_ratio(-mean_difference_cents + 2)\n",
    "# pitch = torch.clip(pitch, promonet.FMIN, promonet.FMAX)\n",
    "\n",
    "# Edit\n",
    "edited_ppg = ppg.clone()\n",
    "# edited_ppg = ppgs.edit.regex(edited_ppg[0].cpu(), ['b', 'aa'], ['b', 'aw'])[None].to('cuda:0')\n",
    "# edited_ppg = ppgs.edit.reallocate(edited_ppg[0], 'ay', 'aw')[None]\n",
    "# edited_ppg = ppgs.edit.reallocate(edited_ppg[0], 'aa', 'ah', )[None]\n",
    "# edited_ppg = ppgs.edit.reallocate(edited_ppg[0], 'ae', 'ah', )[None]\n",
    "# edited_ppg = ppgs.edit.reallocate(edited_ppg[0], 'eh', 'ah', )[None]\n",
    "# edited_ppg = ppgs.edit.reallocate(edited_ppg[0], 'ih', 'ah', )[None]\n",
    "# edited_ppg = ppgs.edit.reallocate(edited_ppg[0], 'ay', 'ao')[None]\n",
    "edited_ppg = ppgs.edit.regex(ppg[0].cpu(), ['dh', 'ah'], ['th', 'ah'], reallocate=True)[None].to('cuda:0')\n",
    "edited_ppg = ppgs.edit.regex(edited_ppg[0].cpu(), ['n', 'aa', 't'], ['n', 'ah', 't'], reallocate=True)[None].to('cuda:0')\n",
    "edited_ppg = ppgs.edit.reallocate(edited_ppg[0], 'er', 'r')[None]\n",
    "edited_ppg = ppgs.edit.reallocate(edited_ppg[0], 'ae', 'ih')[None]\n",
    "\n",
    "\n",
    "# print([p for i, p in enumerate(ppgs.PHONEMES) if ppg[0, i].max() > 1e-6])\n",
    "# edited_ppg = ppgs.edit.reallocate(ppg[0], 's', 'sh')[None]\n",
    "# edited_ppg = ppgs.edit.shift(ppg[0], 'eh', .2)[None]\n",
    "# edited_ppg = ppgs.edit.regex(ppg[0].cpu(), ['hh', 'ae'], ['hh', 'aa'])[None].to('cuda:0')\n",
    "# edited_ppg = ppgs.edit.regex(ppg[0].cpu(), ['uw'], ['aa'])[None].to('cuda:0')\n",
    "# edited_ppg = ppgs.edit.regex(edited_ppg[0].cpu(), ['ah'], ['uh'])[None].to('cuda:0')\n",
    "# edited_ppg = ppgs.edit.reallocate(edited_ppg[0].cpu(), 'dh', 'th')[None].to('cuda:0')\n",
    "# edited_ppg = ppgs.edit.regex(ppg[0].cpu(), ['dh', 'ah'], ['th', 'ah'], reallocate=True)[None].to('cuda:0')\n",
    "# edited_ppg = ppgs.edit.regex(edited_ppg[0].cpu(), ['n', 'aa', 't'], ['n', 'ah', 't'], reallocate=True)[None].to('cuda:0')\n",
    "# edited_ppg = ppgs.edit.reallocate(edited_ppg[0], 'er', 'r')[None]\n",
    "# edited_ppg = ppgs.edit.reallocate(edited_ppg[0], 'ae', 'ih')[None]\n",
    "# edited_ppg = ppg\n",
    "\n",
    "# Synthesize\n",
    "edited = promonet.synthesize.from_features(\n",
    "    loudness,\n",
    "    pitch,\n",
    "    periodicity,\n",
    "    edited_ppg,\n",
    "    speaker=int(speaker),\n",
    "    checkpoint=checkpoint,\n",
    "    gpu=0)\n",
    "\n",
    "# Plot and save results\n",
    "plot(\n",
    "    'thesis/accent',\n",
    "    audio,\n",
    "    edited,\n",
    "    promonet.preprocess.loudness.band_average(loudness, 1),\n",
    "    pitch,\n",
    "    periodicity,\n",
    "    edited_ppg,\n",
    "    highlight='ppg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec10067-f173-4997-9c2a-beceda1091a5",
   "metadata": {},
   "source": [
    "### Automatic onomatopoeia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa86c5f-fd19-4b39-9ce0-dc69abd109d5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Load\n",
    "audio = promonet.load.audio('/hemera-storage1/pardo/max/test-audio/cat.wav').mean(0, keepdim=True)\n",
    "\n",
    "# Preprocess\n",
    "loudness, pitch, periodicity, ppg = promonet.preprocess.from_audio(\n",
    "    audio,\n",
    "    features=['ppg', 'pitch', 'periodicity', 'loudness'],\n",
    "    gpu=0)\n",
    "log_mean_f0 = torch.log2(pitch[periodicity > promonet.VOICING_THRESHOLD]).mean()\n",
    "mean_difference_cents = promonet.convert.ratio_to_cents(2 ** log_mean_f0 / averages[speaker])\n",
    "print(mean_difference_cents)\n",
    "pitch = pitch * promonet.convert.cents_to_ratio(-mean_difference_cents)\n",
    "pitch = torch.clip(pitch, promonet.FMIN, promonet.FMAX)\n",
    "\n",
    "# Synthesize\n",
    "print(\n",
    "    loudness.shape,\n",
    "    pitch.shape,\n",
    "    periodicity.shape,\n",
    "    loudness.shape,\n",
    ")\n",
    "edited = promonet.synthesize.from_features(\n",
    "    loudness,\n",
    "    pitch,\n",
    "    periodicity,\n",
    "    ppg,\n",
    "    speaker=int(speaker),\n",
    "    checkpoint=checkpoint,\n",
    "    gpu=0)\n",
    "\n",
    "# Plot and save results\n",
    "plot(\n",
    "    'thesis/onomatopoeia',\n",
    "    audio,\n",
    "    edited,\n",
    "    promonet.preprocess.loudness.band_average(loudness, 1),\n",
    "    pitch,\n",
    "    periodicity,\n",
    "    ppg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7132d4c-b60e-4575-a622-f6a4ac2cc7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "2 ** log_mean_f0 / averages[speaker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4b26df-c95b-4013-b082-cda7a6890dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppg_down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5524f32-09fc-42b0-b182-9364d8f244a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "promonet",
   "language": "python",
   "name": "promonet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
