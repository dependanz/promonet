{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "30a60a2d-2952-4aa1-8133-9519047bb0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import ppgs\n",
    "from pathlib import Path\n",
    "import promonet\n",
    "import pysodic\n",
    "import numpy as np\n",
    "import json\n",
    "import torchaudio\n",
    "import penn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54e5bf40-d4df-4deb-a69f-a050742e3dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsd = ppgs.evaluate.metrics.jensenShannonDivergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e6155d7-466f-4b85-92c3-795bb901bb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix = torch.load('balanced_similarity.pt')\n",
    "def norm(ppg):\n",
    "    return torch.mm(similarity_matrix.T ** 1, ppg)\n",
    "\n",
    "def ppg_distance(ppg0, ppg1):\n",
    "    return jsd(norm(ppg0), norm(ppg1), reduction=None).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "695397f4-3f11-48bd-a430-86c5eae11423",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'w2v2fb-ppg'\n",
    "subjective_dir = Path('/repos/promonet/data/cache/ppgs-subjective')\n",
    "assert subjective_dir.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3533d2a-b028-442a-997c-bcfdf708386f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_representations = [\n",
    "    'w2v2fb',\n",
    "    'w2v2fc',\n",
    "    'bottleneck',\n",
    "    'mel',\n",
    "    'encodec'\n",
    "]\n",
    "all_models = []\n",
    "all_models += [f'{rep}-ppg' for rep in all_representations]\n",
    "all_models += [f'{rep}-latents' for rep in all_representations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fbe1707d-fd19-4844-82f6-e874494b29c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stems = [p.stem for p in list((subjective_dir / 'original').glob('*-100.wav'))]\n",
    "len(stems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "310dd978-c39e-46a2-b863-aa5f1db57016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['089', '112']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SHIFT_CENTS = [-200, 200]\n",
    "ratios = [2 ** (cents / 1200) for cents in SHIFT_CENTS]\n",
    "ratio_strings = [f'{int(ratio * 100):03d}' for ratio in ratios]\n",
    "ratio_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e2d7f39e-9b64-4bd4-b9d6-c2b699fe0d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w2v2fb-ppg: 0.04583841562271118\n",
      "w2v2fc-ppg: 0.07784371823072433\n",
      "bottleneck-ppg: 0.07088759541511536\n",
      "mel-ppg: 0.05224919691681862\n",
      "encodec-ppg: 0.05325319990515709\n",
      "w2v2fb-latents: 0.0397956520318985\n",
      "w2v2fc-latents: 0.04161763936281204\n",
      "bottleneck-latents: 0.12780499458312988\n",
      "mel-latents: 0.03635498881340027\n",
      "encodec-latents: 0.039325352758169174\n"
     ]
    }
   ],
   "source": [
    "for model in all_models:\n",
    "    total = 0\n",
    "    count = 0\n",
    "    \n",
    "    for stem in stems:\n",
    "        for ratio in ratio_strings:\n",
    "            shifted_stem = stem[:stem.rindex('-')] + f'-{ratio}'\n",
    "            original_ppg = torch.load(subjective_dir / 'original' / (stem + '-w2v2fb-ppg.pt'))\n",
    "            other_ppg = torch.load(subjective_dir / model / (shifted_stem + '-w2v2fb-ppg.pt'))\n",
    "            if original_ppg.shape[-1] - other_ppg.shape[-1] <= 2:\n",
    "                original_ppg = original_ppg[..., :other_ppg.shape[-1]]\n",
    "            assert original_ppg.shape == other_ppg.shape, f'{original_ppg.shape}, {other_ppg.shape}'\n",
    "\n",
    "        total += ppg_distance(original_ppg, other_ppg)\n",
    "        count += other_ppg.shape[-1]\n",
    "    print(f'{model}: {total/count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "44d6219f-32f0-4b0d-9868-7f8d9efe9853",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_representations = [\n",
    "    'w2v2fb',\n",
    "    'w2v2fc',\n",
    "    'bottleneck',\n",
    "    'mel',\n",
    "    'encodec'\n",
    "]\n",
    "all_models = []\n",
    "all_models += [f'{rep}-ppg' for rep in all_representations]\n",
    "# all_models += [f'{rep}-latents' for rep in all_representations]\n",
    "results = {}\n",
    "for model in all_models:\n",
    "    \n",
    "    for stem in stems:\n",
    "        key = f'{model}-{stem[:-4]}'\n",
    "        total = 0\n",
    "        count = 0\n",
    "        for ratio in ratio_strings:\n",
    "            shifted_stem = stem[:stem.rindex('-')] + f'-{ratio}'\n",
    "            original_ppg = torch.load(subjective_dir / 'original' / (stem + '-w2v2fb-ppg.pt'))\n",
    "            other_ppg = torch.load(subjective_dir / model / (shifted_stem + '-w2v2fb-ppg.pt'))\n",
    "            if original_ppg.shape[-1] - other_ppg.shape[-1] <= 2:\n",
    "                original_ppg = original_ppg[..., :other_ppg.shape[-1]]\n",
    "            assert original_ppg.shape == other_ppg.shape, f'{original_ppg.shape}, {other_ppg.shape}'\n",
    "\n",
    "            total += ppg_distance(original_ppg, other_ppg)\n",
    "            count += other_ppg.shape[-1]\n",
    "        results[key] = (total/count).item()\n",
    "with open('jsd.json', 'w+') as f:\n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4d7b3e5a-90df-4421-be34-39db4b56446a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_to_pitch(audio, sample_rate):\n",
    "    return penn.from_audio(\n",
    "        audio,\n",
    "        sample_rate,\n",
    "        hopsize=promonet.convert.samples_to_seconds(promonet.HOPSIZE),\n",
    "        fmin=promonet.FMIN,\n",
    "        fmax=promonet.FMAX,\n",
    "        pad=True,\n",
    "        interp_unvoiced_at=0.1625,\n",
    "        gpu=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0846f96c-ee76-4978-8de5-c62138ea850a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_representations = [\n",
    "    'w2v2fb',\n",
    "    'w2v2fc',\n",
    "    'bottleneck',\n",
    "    'mel',\n",
    "    'encodec'\n",
    "]\n",
    "all_models = []\n",
    "all_models += [f'{rep}-ppg' for rep in all_representations]\n",
    "# all_models += [f'{rep}-latents' for rep in all_representations]\n",
    "results = {}\n",
    "for model in all_models:\n",
    "    \n",
    "    for stem in stems:\n",
    "        key = f'{model}-{stem[:-4]}'\n",
    "        total = 0\n",
    "        count = 0\n",
    "        metrics = pysodic.metrics.Pitch()\n",
    "        for ratio_val, ratio in zip(ratios, ratio_strings):\n",
    "            shifted_stem = stem[:stem.rindex('-')] + f'-{ratio}'\n",
    "            original_audio, original_sr = torchaudio.load(subjective_dir / 'original' / (stem + '.wav'))\n",
    "            other_audio, other_sr = torchaudio.load(subjective_dir / model / (shifted_stem + '.wav'))\n",
    "            \n",
    "            original_pitch, original_periodicity = audio_to_pitch(original_audio, original_sr)\n",
    "            original_pitch = original_pitch * ratio_val\n",
    "            other_pitch, other_periodicity = audio_to_pitch(other_audio, other_sr)\n",
    "            \n",
    "            if original_pitch.shape[-1] - other_pitch.shape[-1] <= 2:\n",
    "                original_pitch = original_pitch[..., :other_pitch.shape[-1]]\n",
    "                original_periodicity = original_periodicity[..., :other_periodicity.shape[-1]]\n",
    "            assert original_pitch.shape == other_pitch.shape, f'{original_pitch.shape}, {other_pitch.shape}'\n",
    "            assert original_periodicity.shape == other_periodicity.shape, f'{original_periodicity.shape}, {other_periodicity.shape}'\n",
    "            \n",
    "            original_voicing = original_periodicity > 0.1625\n",
    "            other_voicing = other_periodicity > 0.1625\n",
    "\n",
    "            metrics.update(original_pitch, original_voicing, other_pitch, other_voicing)\n",
    "        results[key] = metrics()\n",
    "with open('pitch.json', 'w+') as f:\n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "376f2332-cccd-4daa-8709-a13dda752ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_representations = [\n",
    "    'w2v2fb',\n",
    "    'w2v2fc',\n",
    "    'bottleneck',\n",
    "    'mel',\n",
    "    'encodec'\n",
    "]\n",
    "all_models = []\n",
    "all_models += [f'{rep}-ppg' for rep in all_representations]\n",
    "# all_models += [f'{rep}-latents' for rep in all_representations]\n",
    "results = {}\n",
    "for model in all_models:\n",
    "\n",
    "    for stem in stems:\n",
    "        key = f'{model}-{stem[:-4]}'\n",
    "        total = 0\n",
    "        count = 0\n",
    "        metrics = promonet.evaluate.metrics.WER(gpu=0)\n",
    "        for ratio in ratio_strings:\n",
    "            shifted_stem = stem[:stem.rindex('-')] + f'-{ratio}'\n",
    "            speaker = stem.split('-')[0]\n",
    "            stem_sans_speaker = stem[stem.index('-')+1:][:-4]\n",
    "            text = promonet.load.text(promonet.CACHE_DIR / 'vctk' / speaker / (stem_sans_speaker + '.txt'))\n",
    "            metrics.update(text, str(subjective_dir / model / (shifted_stem + '.wav')))\n",
    "        results[key] = metrics()\n",
    "with open('wer.json', 'w+') as f:\n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92607a83-44ef-43b8-a609-574041c7e11b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
